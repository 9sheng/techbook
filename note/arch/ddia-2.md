# 第五章 复制

### 领导者与追随者
- 副本之一被指定为领导者（leader），也称为主库（master） ，首要（primary）。当客户端要向数据库写入时，它必须将请求发送给领导者，领导者会将新数据写入其本地存储。
- 其他副本被称为追随者（followers），亦称为只读副本（read replicas），从库（slaves），次要（ sencondaries），热备（hot-standby）。每当领导者将新数据写入本地存储时，它也会将数据变更发送给所有的追随者，称之为复制日志（replication log）记录或变更流（change stream）。
- 当客户想要从数据库中读取数据时，它可以向领导者或追随者查询。 但只有领导者才能接受写操作（从客户端的角度来看从库都是只读的）。
- 不同的人对热（hot），温（warn），冷（cold） 备份服务器有不同的定义。 例如在PostgreSQL中，**热备（hot standby）**指的是能接受客户端读请求的副本。而**温备（warm standby）**只是追随领导者，但不处理客户端的任何查询。

### 同步复制 vs 异步复制
- 将所有从库都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。
- 如果在数据库上启用同步复制，通常意味着其中一个跟随者是同步的，而其他的则是异步的。如果同步从库变得不可用或缓慢，则使一个异步从库同步。这保证至少在两个节点上拥有最新的数据副本：主库和同步从库。 这种配置有时也被称为**半同步（semi-synchronous）**。
- 对于异步复制系统而言，主库故障时有可能丢失数据。这可能是一个严重的问题，因此研究人员仍在研究不丢数据但仍能提供良好性能和可用性的复制方法。 例如，链式复制是同步复制的一种变体，已经在一些系统（如Microsoft Azure存储）中成功实现。

### 复制日志
- 基于语句（statement）的复制：主库记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库。
- 预写式日志（Write Ahead Log, WAL）： 对于日志结构存储引擎，日志是主要的存储位置。日志段在后台压缩，并进行垃圾回收。对于覆写单个磁盘块的B树，每次修改都会先写入预写式日志（WAL），以便崩溃后索引可以恢复到一个一致的状态。日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：除了将日志写入磁盘之外，主库还可以通过网络将其发送给其从库。
- 逻辑日志复制（基于行）：复制和存储引擎使用不同的日志格式，这样可以使复制日志从存储引擎内部分离出来。这种复制日志被称为逻辑日志，以将其与存储引擎的（物理）数据表示区分开来。
 - 基于触发器的复制：触发器允许您注册在数据库系统中发生数据更改（写入事务）时自动执行的自定义应用程序代码。触发器有机会将更改记录到一个单独的表中，使用外部程序读取这个表，再加上任何业务逻辑处理，会后将数据变更复制到另一个系统去。例如，Databus for Oracle和Bucardo for Postgres。

### 复制延迟（一致性读）
- **读己之写**： 读写一致性（read-after-write consistency），也称为读己之写一致性（read-your-writes consistency），实现技术很多，如：
  - 都从主库读
  - 以跟踪上次更新的时间，在上次更新后的一分钟内，从主库读。还可以监控从库的复制延迟，防止任向任何滞后超过一分钟到底从库发出查询
  - 客户端可以记住最近一次写入的时间戳，系统需要确保从库为该用户提供任何查询时，该时间戳前的变更都已经传播到了本从库中。如果当前从库不够新，则可以从另一个从库读，或者等待从库追赶上来，时间戳可以是逻辑时间戳（指示写入顺序的东西，例如日志序列号）或实际系统时钟（在这种情况下，时钟同步变得至关重要）
- **单调读（Monotonic reads）**
  - 比强一致性（strong consistency）更弱，但比最终一致性（eventually consistency）更强的保证，不会看到时间倒退
  - 一种方式是确保每个用户总是从同一个副本进行读取
- **一致前缀读（consistent prefix reads）**：如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现
  - 不一致前缀读，是分区（partitioned）（分片（sharded））数据库中的一个特殊问题。如果数据库总是以相同的顺序应用写入，则读取总是会看到一致的前缀，所以这种异常不会发生。但是在许多分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序：当用户从数据库中读取数据时，可能会看到数据库的某些部分处于较旧的状态，而某些处于较新的状态。

### 多主复制
- 最大问题是可能发生写冲突
- 同步与异步冲突检测：可能会失去多主的优势
- 冲突避免：处理冲突的最简单的策略就是避免它们
  - 收敛至一致的状态：单主数据库按顺序应用写操作：如果同一个字段有多个更新，则最后一个写操作将确定该字段的最终值
    - 给每个写入一个唯一的ID（例如，一个时间戳，一个长的随机数，一个UUID或者一个键和值的哈希），挑选最高ID的写入作为胜利者
    - 为每个副本分配一个唯一的ID，ID编号更高的写入具有更高的优先级
    - 以某种方式将这些值合并在一起
    - 在保留所有信息的显式数据结构中记录冲突，并编写解决冲突的应用程序代码（也许通过提示用户的方式）

### 无主复制
- 如果有n个副本，每个写入必须由w节点确认才能被认为是成功的，并且我们必须至少为每个读取查询 r 个节点，只要 $w + r > n$
- 尽管法定人数似乎保证读取返回最新的写入值，但在实践中并不那么简单。 Dynamo风格的数据库通常针对可以忍受最终一致性的用例进行优化。允许通过参数w和r来调整读取陈旧值的概率，但把它们当成绝对的保证是不明智的
- 即使在 $w + r> n$ 的情况下，也可能存在返回陈旧值的边缘情况，取决于实现，包括：
  - 使用**松散的法定人数（sloppy quorum，写入指定n节点之外的节点）** 和带提示的接力（hinted handoff）
  - 如果两个写入同时发生，不清楚哪一个先发生。在这种情况下，唯一安全的解决方案是合并并发写入，数据丢失
  - 读和写同时发生，不确认读的是新值还是旧值
  - 没有写成 w 个副本，有的成功了，但没回滚
  - 有时也会不幸地出现关于时序（timing）的边缘

## 第六章 分区
分区（partitions），也称为分片（sharding），分区主要是为了可扩展性。不同的分区可以放在不共享集群中的不同节点上。

### 根据键的范围分区
键是有序的，并且分区拥有从某个最小值到某个最大值的所有键。排序的优势在于可以进行有效的范围查询，但是如果应用程序经常访问相邻的主键，则存在热点的风险。这种方法中，当分区变得太大时，通常将分区分成两个子分区，动态地再平衡分区。

### 根据键的散列分区
- 散列函数应用于每个键，分区拥有一定范围的散列。这种方法破坏了键的排序，使得范围查询效率低下，但可以更均匀地分配负载。
  - 散列函数不需要多么强壮的加密算法：例如，Cassandra和MongoDB使用MD5，Voldemort使用Fowler-Noll-Vo函数
  - 一致性哈希由Karger等人定义。用于跨互联网级别的缓存系统，例如CDN中，是一种能均匀分配负载的方法。它使用随机选择的分区边界（partition boundaries）来避免中央控制或分布式一致性的需要，描述了重新平衡的特定方法
  - 负载倾斜与消除热点，主键后加随机数，但读会更复杂
- 有两种用二级索引对数据库进行分区的方法：基于文档的分区（document-based）和基于关键词（term-based）的分区。
  - 按文档的二级索引
    - 每个分区是完全独立的：每个分区维护自己的二级索引，仅覆盖该分区中的文档。它不关心存储在其他分区的数据。文档分区索引也被称为本地索引（local index）。
    - 如果要搜索，则需要将查询发送到所有分区，并合并所有返回的结果。这种查询分区数据库的方法有时被称为分散/聚集（scatter/gather），并且可能会使二级索引上的读取查询相当昂贵。
    - MonDBDB，Riak ，Cassandra ，Elasticsearch ，SolrCloud 和VoltDB 都使用文档分区二级索引
  - 根据关键词（Term）的二级索引
    - 一个覆盖所有分区数据的全局索引
    - 关键词分区的全局索引优于文档分区索引的地方点是它可以使读取更有效率：不需要分散/收集所有分区，客户端只需要向包含关键词的分区发出请求。全局索引的缺点在于写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区

### 分区再平衡
将负载从集群中的一个节点向另一个节点移动的过程称为再平衡（reblancing）
- 要求
  - 再平衡之后，负载（数据存储，读取和写入请求）应该在集群中的节点之间公平地共享。
  - 再平衡发生时，数据库应该继续接受读取和写入。
  - 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I/O负载。
- 常见策略
  - 反面教材：hash mod N，如果节点数量N发生变化，大多数密钥将需要从一个节点移动到另一个节点
  - 固定数量的分区：创建比节点更多的分区，并为每个节点分配多个分区。例如，运行在10个节点的集群上的数据库可能会从一开始就被拆分为1,000个分区，因此大约有100个分区被分配给每个节点。缺点：如果数据集的总大小难以预估（例如，如果它开始很小，但随着时间的推移可能会变得更大），选择正确的分区数是困难的。分区过多时，分区管理也会耗费过多的资源。
  - 动态分区：当分区增长到超过配置的大小时（在HBase上，默认值是10GB），会被分成两个分区，每个分区约占一半的数据。与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。动态分区的一个优点是分区数量适应总数据量。如果只有少量的数据，少量的分区就足够了，所以开销很小，如果有大量的数据，每个分区的大小被限制在一个可配置的最大值。动态分区和固定分区两种方法搭配使用也是可行的，例如使用复合主键：使用键的一部分来标识分区，而使用另一部分作为排序顺序。
  - 按节点比例分区。通过动态分区，分区的数量与数据集的大小成正比，因为拆分和合并过程将每个分区的大小保持在固定的最小值和最大值之间。另一方面，对于固定数量的分区，每个分区的大小与数据集的大小成正比。在这两种情况下，分区的数量都与节点的数量无关。 Cassandra和Ketama使用的第三种方法是使分区数与节点数成正比——换句话说，每个节点具有固定数量的分区。当一个新节点加入集群时，它随机选择固定数量的现有分区进行拆分，然后占有这些拆分分区中每个分区的一半，同时将每个分区的另一半留在原地。

### 请求路由：服务发现
- 允许客户联系任何节点（例如，通过循环策略的负载均衡（Round-Robin Load Balancer））。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求；否则，它将请求转发到适当的节点，接收回复并传递给客户端。
- 首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求；它仅负责分区的负载均衡。
- 要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介。

# 第七章 事务
> 在数据系统的残酷现实中，很多事情都可能出错：
数据库软件、硬件可能在任意时刻发生故障（包括写操作进行到一半时）。
应用程序可能在任意时刻崩溃（包括一系列操作的中间）。
网络中断可能会意外切断数据库与应用的连接，或数据库之间的连接。
多个客户端可能会同时写入数据库，覆盖彼此的更改。
客户端可能读取到无意义的数据，因为数据只更新了一部分。
客户之间的竞争条件可能导致令人惊讶的错误。

- 事务是应用程序将多个读写操作组合成一个逻辑单元的一种方式。从概念上讲，事务中的所有读写操作被视作单个操作来执行：整个事务要么成功（提交（commit））要么失败（中止（abort），回滚（rollback））事务是一个抽象层，允许应用程序假装某些并发问题和某些类型的硬件和软件故障不存在。各式各样的错误被简化为一种简单情况：事务中止（transaction abort），而应用需要的仅仅是重试。
- 事务所提供的安全保证，通常由众所周知的首字母缩略词ACID来描述，ACID代表原子性（Atomicity），一致性（Consistency），隔离性（Isolation）和持久性（Durability）。高层次上的想法是合理的，但魔鬼隐藏在细节里。今天，当一个系统声称自己“符合ACID”时，实际上能期待的是什么保证并不清楚。
- 不符合ACID标准的系统有时被称为BASE，它代表基本可用性（Basically Available），软状态（Soft State）和最终一致性（Eventual consistency）
  - 原子性的定义特征是：能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。 或许 可中止性（abortability） 是更好的术语
  - 在ACID的上下文中，一致性是指数据库在应用程序的特定概念中处于“良好状态”，在CAP定理中，一致性一词用于表示可线性化；副本一致性，以及异步复制系统中的最终一致性问题；一致性哈希
  - ACID意义上的隔离性意味着，同时执行的事务是相互隔离的：它们不能相互冒犯。传统的数据库教科书将隔离性形式化为可序列化（Serializability），这意味着每个事务可以假装它是唯一在整个数据库上运行的事务。在Oracle中有一个名为“可序列化”的隔离级别，但实际上它实现了一种叫做快照隔离（snapshot isolation） 的功能，这是一种比可序列化更弱的保证
  - 持久性 是一个承诺，即一旦事务成功完成，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。在历史上，持久性意味着写入归档磁带。后来它被理解为写入硬盘或SSD，最近它已经适应了“复制（replication）”的新内涵
>- 如果你写入磁盘然后机器宕机，即使数据没有丢失，在修复机器或将磁盘转移到其他机器之前，也是无法访问的。这种情况下，复制系统可以保持可用性。
> - 一个相关性故障（停电，或一个特定输入导致所有节点崩溃的Bug）可能会一次性摧毁所有副本，任何仅存储在内存中的数据都会丢失，故内存数据库仍然要和磁盘写入打交道。
> - 在异步复制系统中，当主库不可用时，最近的写入操作可能会丢失。
> - 当电源突然断电时，特别是固态硬盘，有证据显示有时会违反应有的保证：甚至fsync也不能保证正常工作。硬盘固件可能有错误，就像任何其他类型的软件一样。
> - 存储引擎和文件系统之间的微妙交互可能会导致难以追踪的错误，并可能导致磁盘上的文件在崩溃后被损坏。
> - 磁盘上的数据可能会在没有检测到的情况下逐渐损坏。如果数据已损坏一段时间，副本和最近的备份也可能损坏。这种情况下，需要尝试从历史备份中恢复数据。
> - 一项关于固态硬盘的研究发现，在运行的前四年中，30％到80％的硬盘会产生至少一个坏块。相比固态硬盘，磁盘的坏道率较低，但完全失效的概率更高。
> - 如果SSD断电，可能会在几周内开始丢失数据，具体取决于温度。

### 隔离
- 弱隔离级别（不可串行化（nonserializable））：数据库一直试图通过提供事务隔离（transaction isolation） 来隐藏应用程序开发者的并发问题。从理论上讲，隔离可以通过假装没有并发发生，让你的生活更加轻松：可序列化（serializable） 的隔离等级意味着数据库保证事务的效果与连续运行（即一次一个，没有任何并发）是一样的。
- **读已提交（Read Committed）**
  - 从数据库读时，只能看到已提交的数据（没有脏读（dirty reads）），写入数据库时，只会覆盖已经写入的数据（没有脏写（dirty writes））。某些数据库支持甚至更弱的隔离级别，称为读未提交（Read uncommitted）。它可以防止脏写，但不防止脏读。
  - 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置。
  - 最常见的情况是，数据库通过使用行锁（row-level lock） 来防止脏写，但由于性能原因，大多数数据库对于写入的每个对象，数据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 只有当新值提交后，事务才会切换到读取新值。
- **快照隔离和可重复读**
  - 快照隔离是一个有用的隔离级别，特别对于只读事务而言。但是，许多数据库实现了它，却用不同的名字来称呼。在Oracle中称为可序列化（Serializable）的，在PostgreSQL和MySQL中称为可重复读（repeatable read）
  - 快照隔离的实现通常使用写锁来防止脏写，**这意味着进行写入的事务会阻止另一个事务修改同一个对象**。但是读取不需要任何锁定。从性能的角度来看，快照隔离的一个关键原则是：读不阻塞写，写不阻塞读。它并排维护着多个版本的对象，所以这种技术被称为多版本并发控制（MVCC, multi-version concurrentcy control）。如果一个数据库只需要提供读已提交的隔离级别，而不提供快照隔离，那么保留一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本。支持快照隔离的存储引擎通常也使用MVCC来实现读已提交隔离级别。一种典型的方法是读已提交为每个查询使用单独的快照，而快照隔离对整个事务使用相同的快照。
  - **不可重复读（nonrepeatable read）或读取偏差（read skew）**： 在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。快照隔离经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。快照隔离通常使用多版本并发控制（MVCC） 来实现。
  - **更新丢失（lost updates）**：两个客户端同时执行读取-修改-写入序列。其中一个写操作，在没有合并另一个写入变更情况下，直接覆盖了另一个写操作的结果。所以导致数据丢失。快照隔离的一些实现可以自动防止这种异常，而另一些实现则需要手动锁定（SELECT FOR UPDATE）。数据库可以结合快照隔离高效地执行此检查。事实上，PostgreSQL的可重复读，Oracle的可串行化和SQL Server的快照隔离级别，都会自动检测到丢失更新，并中止惹麻烦的事务。但是，MySQL/InnoDB的可重复读并不会检测丢失更新。一些作者认为，数据库必须能防止丢失更新才称得上是提供了快照隔离，所以在这个定义下，MySQL下不提供快照隔离。
  - **写偏差（write skew）**：一个事务读取一些东西，根据它所看到的值作出决定，并将决定写入数据库。但是，写作的时候，决定的前提不再是真实的。只有可序列化的隔离才能防止这种异常。在PostgreSQL的可重复读，MySQL/InnoDB的可重复读，Oracle可序列化或SQL Server的快照隔离级别中，都不会自动检测写入偏差。自动防止写入偏差需要真正的可序列化隔离。（查询没有返回任何行，则SELECT FOR UPDATE锁不了任何东西。）
  - **幻读（phantom reads）**：事务读取符合某些搜索条件的对象。另一个客户端进行写入，影响搜索结果。快照隔离可以防止直接的幻像读取，但是写入歪斜环境中的幻影需要特殊处理，例如索引范围锁定。快照隔离避免了只读查询中幻读，但是在像我们讨论的例子那样的读写事务中，幻影会导致特别棘手的写偏差情况。
- **可序列化（serializability）隔离**通常被认为是最强的隔离级别。它保证即使事务可以并行执行，最终的结果也是一样的，就好像它们没有任何并发性，连续挨个执行一样。因此数据库保证，如果事务在单独运行时正常运行，则它们在并发运行时继续保持正确 —— 换句话说，数据库可以防止所有可能的竞争条件。目前大多数提供可序列化的数据库都使用了三种技术之一：
  - **字面意义上地串行顺序执行事务（真的串行执行）**
    - 数据库设计人员只是在2007年左右才决定， 因为RAM此时才足够便宜，数据库设计人员意识到OLTP事务通常很短，而且只进行少量的读写操作，串行执行事务的方法在VoltDB/H-Store，Redis和Datomic中实现。
    - 每个事务都必须小而快，只要有一个缓慢的事务，就会拖慢所有事务处理。
    - 仅限于活跃数据集可以放入内存的情况。很少访问的数据可能会被移动到磁盘，但如果需要在单线程执行的事务中访问，系统就会变得非常慢。
    - 写入吞吐量必须低到能在单个CPU核上处理，如若不然，事务需要能划分至单个分区，且不需要跨分区协调。
    - 跨分区事务是可能的，但是它们的使用程度有很大的限制。
  - **两阶段锁（2PL, two-phase locking）**
    - 大约30年来唯一可行的选择
    - 在2PL中，写入不仅会阻塞其他写入，也会阻塞读，反之亦然。快照隔离使得读不阻塞写，写也不阻塞读，这是2PL和快照隔离之间的关键区别。
    - 2PL用于MySQL（InnoDB）和SQL Server中的可序列化隔离级别，以及DB2中的可重复读隔离级别。
    - 读与写的阻塞是通过为数据库中每个对象添加锁来实现的。锁可以处于共享模式（shared mode）或独占模式（exclusive mode）。
    - 两阶段锁定的巨大缺点，以及70年代以来没有被所有人使用的原因，是其性能问题。两阶段锁定下的事务吞吐量与查询响应时间要比弱隔离级别下要差得多。
    - 断言锁（predicate lock）如果事务A想要读取匹配某些条件的对象，就像在这个 SELECT 查询中那样，它必须获取查询条件上的共享断言锁（shared-mode predicate lock）。如果另一个事务B持有任何满足这一查询条件对象的排它锁，那么A必须等到B释放它的锁之后才允许进行查询。
    - 如果活跃事务持有很多锁，检查匹配的锁会非常耗时。因此，大多数使用2PL的数据库实际上实现了索引范围锁（也称为间隙锁（next-key locking））
    - 两阶段锁是一种所谓的悲观并发控制机制（pessimistic） ：它是基于这样的原则：如果有事情可能出错（如另一个事务所持有的锁所表示的），最好等到情况安全后再做任何事情。这就像互斥，用于保护多线程编程中的数据结构。
  - **可序列化的快照隔离（serializable snapshot isolation, SSI）**，乐观并发控制技术
    - 一方面，我们实现了性能不好（2PL）或者扩展性不好（串行执行）的可序列化隔离级别。另一方面，我们有性能良好的弱隔离级别，但容易出现各种竞争条件（丢失更新，写入偏差，幻读等）。它在2008年首次被描述，并且是Michael Cahill的博士论文的主题
    - 序列化快照隔离是一种乐观（optimistic） 的并发控制技术。在这种情况下，乐观意味着，如果存在潜在的危险也不阻止事务，而是继续执行事务，希望一切都会好起来。当一个事务想要提交时，数据库检查是否有什么不好的事情发生（即隔离是否被违反）；如果是的话，事务将被中止，并且必须重试。只有可序列化的事务才被允许提交。
    - 数据库需要跟踪一个事务由于MVCC可见性规则而忽略另一个事务的写入。当事务想要提交时，数据库检查是否有任何被忽略的写入现在已经被提交。如果是这样，事务必须中止。
    - 与两阶段锁定相比，可序列化快照隔离的最大优点是一个事务不需要阻塞等待另一个事务所持有的锁。就像在快照隔离下一样，写不会阻塞读，反之亦然。这种设计原则使得查询延迟更可预测，变量更少。特别是，只读查询可以运行在一致的快照上，而不需要任何锁定，这对于读取繁重的工作负载非常有吸引力。
    - 与串行执行相比，可序列化快照隔离并不局限于单个CPU核的吞吐量：FoundationDB将检测到的序列化冲突分布在多台机器上，允许扩展到很高的吞吐量。
    - 中止率显着影响SSI的整体表现。例如，长时间读取和写入数据的事务很可能会发生冲突并中止，因此SSI要求同时读写的事务尽量短（只读长事务可能没问题）。对于慢事务，SSI可能比两阶段锁定或串行执行更不敏感。
