<!-- toc -->
# 第一章：可靠性，可扩展性，可维护性
### 可靠性
- **故障（fault）**不同于**失效（failure）**。故障通常定义为系统的一部分状态偏离其标准，而失效则是系统作为一个整体停止向用户提供服务。故障的概率不可能降到零，因此最好设计容错机制以防因故障而导致失效。
- 硬盘的平均无故障时间（MTTF, mean time to failure）约为10到50年，从数学期望上讲，10000个磁盘平均每天会有1个磁盘出故障。

### 可扩展性
- 性能指标
  - 对于批处理系统，通常关心的是**吞吐量（throughput）**，即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间；对于在线系统，通常更重要的是服务的**响应时间（response time）**，即客户端发送请求到接收响应之间的时间。
  - **延迟（latency）**和**响应时间（response time）**经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的**服务时间（service time）**之外，还包括网络延迟和排队延迟；延迟是某个请求等待处理的持续时长，在此期间它处于休眠（latent）状态，并等待服务。
- 性能描述
  - 通常使用**百分位点（percentiles）**比平均值更好，常用的有**中位数（median）**、95%、99%、99.9%（p50, p95, p99, p999）；百分位点通常用于**服务级别目标（SLO, service level objectives）**和**服务级别协议（SLA, service level agreements）**，即定义服务预期性能和可用性的合同。
  - 响应时间的高百分位点，**尾部延迟（tail latencies）**非常重要，因为他们直接影响用户的服务体验。例如亚马逊在描述内部服务的响应时间要求时以99.9百分位点为准，即使它只影响一千个请求中的一个。另一方面，优化第99.99百分位点（一万个请求中最慢的一个）被认为太昂贵。
  - 排队延迟（queueing delay）通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其CPU核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为**头部阻塞（head-of-line blocking）**。
- **纵向扩展（scaling up）**或**垂直扩展（vertical scaling）**，转向更强大的机器；**横向扩展（scaling out）**或**水平扩展（horizontal scaling）**，将负载分布到多台小机器上之间的对立。
- 一个良好适配应用的可扩展架构，是围绕着**假设（assumption）**建立的：哪些操作是常见的？哪些操作是罕见的？这就是所谓负载参数。如果假设最终是错误的，那么为扩展所做的工程投入就白费了，最糟糕的是适得其反。

### 可维护性
- 软件系统的三个设计原则
  - **可操作性（Operability）**便于运维团队保持系统平稳运行。如良好的监控，自动化运维支持，良好的文档，易于理解的操作模型，良好的默认行为，有条件的自我修复，行为可预测等。
  - **简单性（Simplicity）**从系统中消除尽可能多的复杂度（complexity），使新工程师也能轻松理解系统。**复杂度（complexity）**有各种可能的症状，如状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的Hack、需要绕开的特例等用于消除额外复杂度的最好工具之一是**抽象（abstraction）**。一个好的抽象可以将大量实现细节隐藏在一个干净、简单易懂的外观下。
  - **可演化性（evolability）**使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为**可扩展性（extensibility）**，**可修改性（modifiability）**或**可塑性（plasticity）**。

# 第二章：数据模型与查询语言
- 在历史上，数据最开始被表示为一棵大树（层次数据模型），但是这不利于表示多对多的关系，所以发明了关系模型来解决这个问题。新的非关系型“NoSQL”数据存储在两个主要方向上存在分歧：
  - 文档数据库：数据通常是自我包含的，而且文档之间的关系非常稀少。
  - 图形数据库：任意事物都可能与任何事物相关联。
- 文档数据库和图数据库有一个共同点：它们通常不会为存储的数据强制一个模式，这使应用程序更容易适应不断变化的需求。但是应用程序很可能仍会假定数据具有一定的结构；这只是模式是明确的（写入时强制）还是隐含的（读取时处理）的问题。
- MySQL是一个值得注意的例外，它执行ALTER TABLE时会复制整个表（可以使用测试数据执行，查看 affected rows，淘宝、腾讯、fb都有辅助工具），这可能意味着在更改一个大型表时会花费几分钟甚至几个小时的停机时间。

# 第三章 存储与检索
### 两大类存储引擎
- 事务处理（OLTP）：通常面向用户，这意味着他们可能会看到大量的请求。为了处理负载，应用程序通常只触及每个查询中的少量记录。应用程序使用某种键来请求记录，存储引擎使用**索引**来查找所请求的键的数据。**磁盘寻道时间**往往是这里的瓶颈。
- 优化分析（OLAP）：主要由业务分析人员使用，而不是由最终用户使用。它们处理比OLTP系统少得多的查询量，但是每个查询通常要求很高，需要在短时间内扫描数百万条记录。**磁盘带宽（不是查找时间）**往往是瓶颈，**列式存储**是这种工作负载越来越流行的解决方案。

### 常用索引
- 哈希索引
  - 键值存储与在大多数编程语言中可以找到的字典（dictionary）类型非常相似，通常字典都是用散列映射（hash map）或哈希表（hash table）实现的。
- OLTP日志结构学派
  - 只允许附加到文件和删除过时的文件，但不会更新已经写入的文件。 Bitcask，SSTables（Sorted Strings Table），LSM树（Log-structured merge-tree），LevelDB，Cassandra，HBase，Lucene等都属于这个组。日志结构的存储引擎是相对较新的发展。他们的主要想法是，系统地**将随机访问写入顺序写入磁盘**，由于硬盘驱动器和固态硬盘的性能特点，可以实现更高的写入吞吐量。
  - 如何避免最终用完磁盘空间？一种好的解决方案是，将日志分为特定大小的段，当日志增长到特定尺寸时关闭当前段文件，并开始写入一个新的段文件。然后，我们就可以对这些段进行压缩（compaction，压缩意味着在日志中丢弃重复的键，只保留每个键的最近更新）
  - SSTable提供一个可持久化[persistent]，有序的、不可变的从键到值的映射关系，其中键和值都是任意字节长度的字符串。SSTable提供了以下操作：按照某个键来查询关联值，可以指定键的范围，来遍历其中所有的键值对。每个SSTable内部由一系列块（block）组成（通常每块大小为64KB，是可配置的）。使用存储在SSTable结尾的块索引（block index）来定位块；当SSTable打开时，索引会被加载到内存里。一次磁盘寻道（disk seek）就可以完成查询（lookup）操作：首先通过二分查找在存储在内存的索引中找到对应的块，然后从磁盘上读取这块内容。SSTable也可以完整地映射到内存里，这样在执行查询和扫描（scan）的时候就不用操作磁盘了。
  - LSM树原理把一棵大树拆分成N棵小树，它首先写入内存中，随着小树越来越大，内存中的小树会flush到磁盘中，磁盘中的树定期可以做merge操作，合并成一棵大树，以优化读性能。
  - 用SSTables制作LSM树
    1. 写入时，将其添加到内存中的平衡树数据结构（例如，红黑树（nginx的timer，epool内核实现，的linux进程调度Completely Fair Scheduler，stl的map）、跳表（leveldb、redis））。这个内存树有时被称为内存表（memtable）
    1. 当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘
    1. 为了提供读取请求，首先尝试在内存表中找到关键字，然后在最近的磁盘段中，然后在下一个较旧的段中找到该关键字
    1. 有时会在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值
  - 如果数据库崩溃，则最近的写入（在内存表中，但尚未写入磁盘）将丢失。为了避免这个问题，可以在磁盘上保存一个单独的日志，每个写入都会立即被附加到磁盘上，每当内存表写出到SSTable时，相应的日志都可以被丢弃。
  - 大量的细节使得存储引擎在实践中表现良好。但当查找数据库中不存在的键时，LSM树算法可能会很慢：您必须检查内存表，然后将这些段一直回到最老的（可能必须从磁盘读取每一个，然后才能确定键不存在）。为了优化这种访问，存储引擎通常使用额外的**Bloom过滤器**。
- OLTP就地更新学派
  - 将磁盘视为一组可以覆盖的固定大小的页面。 B树是这种哲学的最大的例子，被用在所有主要的关系数据库中，还有许多非关系数据库。
  - B树将数据库分解成固定大小的块或页面，传统上大小为4KB（有时会更大），并且一次只能读取或写入一个页面。这种设计更接近于底层硬件，因为磁盘也被安排在固定大小的块中。
  - 大多数数据库可以放入一个三到四层的B树，所以你不需要遵追踪多页面引用来找到你正在查找的页面。（分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB）。
  - 为了使数据库对崩溃具有韧性，B树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log），也称为重做日志（redo log）。这是一个仅追加的文件，每个B树修改都可以应用到树本身的页面上。当数据库在崩溃后恢复时，这个日志被用来使B树恢复到一致的状态
  - 反直觉的是，内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。即使是基于磁盘的存储引擎也可能永远不需要从磁盘读取，因为操作系统缓存最近在内存中使用了磁盘块。相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。
- 其他索引结构
  - 索引中的关键字是查询搜索的内容，如果值是实际行（文档，顶点）在别处的引用，行被存储的地方被称为**堆文件（heap file）**，并且存储的数据没有特定的顺序（它可以是仅附加的，或者可以跟踪被删除的行以便用新数据覆盖它们后来）。
  - 在某些情况下，从索引到堆文件的额外跳跃对读取来说性能损失太大，因此可能希望将索引行直接存储在索引中。这被称为**聚集索引**。例如，在MySQL的InnoDB存储引擎中，表的主键总是一个聚簇索引，二级索引用主键（而不是堆文件中的位置）。
  - 在聚集索引（clustered index）（在索引中存储所有行数据）和非聚集索引（nonclustered index）（仅在索引中存储对数据的引用）之间的折衷被称为**包含列的索引（index with included columns）**或**覆盖索引（covering index）**，其存储表的一部分在索引内。这允许通过单独使用索引来回答一些查询（这种情况叫做索引覆盖了查询）。
- 列存储
  - 列存储在关系数据模型中是最容易理解的，但它同样适用于非关系数据。例如，Parquet是一种列式存储格式，支持基于Google的Dremel 的文档数据模型。面向列的存储布局依赖于包含相同顺序行的每个列文件。 因此，如果您需要重新组装整行，您可以从每个单独的列文件中获取第23项，并将它们放在一起形成表的第23行。
  - 列压缩：一列中不同值的数量与行数相比较小（例如，零售商可能有数十亿的销售交易，但只有100,000个不同的产品）。现在我们可以得到一个有 n 个不同值的列，并把它转换成 n 个独立的位图：每个不同值的一个位图，每行一位。如果该行具有该值，则该位为 1 ，否则为 0 。

- 比较B树和LSM树
  - 存取速度
    - LSM树的写入速度更快，但读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。
    - B树的读取速度更快，但写入慢，B树索引必须至少两次写入每一段数据：一次写入预先写入日志，一次写入树页面本身（也许再次分页），即使在该页面中只有几个字节发生了变化，也需要一次编写整个页面的开销。有些存储引擎甚至会覆盖同一个页面两次，以免在电源故障的情况下导致页面部分更新。
  - 空间开销
    - LSM树可以被压缩得更好，因此经常比B树在磁盘上产生更小的文件。由于LSM树不是面向页面的，并且定期重写SSTables以去除碎片，所以它们具有较低的存储开销。
    - B树存储引擎会由于分割而留下一些未使用的磁盘空间：当页面被拆分或某行不能放入现有页面时，页面中的某些空间仍未被使用。
  - 吞吐量
    - 由于反复压缩和合并SSTables，日志结构索引也会重写数据。这种影响在数据库的生命周期中写入数据库导致对磁盘的多次写入被称为写放大（write amplification）LSM树通常能够比B树支持更高的写入吞吐量，部分原因是它们有时具有较低的写放大。
  - 其他
    - B树的一个优点是每个键只存在于索引中的一个位置，而日志结构化的存储引擎可能在不同的段中有相同键的多个副本。这个方面使得B树在想要提供强大的事务语义的数据库中很有吸引力：在许多关系数据库中，事务隔离是通过在键范围上使用锁来实现的，在B树索引中，这些锁可以直接连接到树。
    - 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。尽管存储引擎尝试逐步执行压缩而不影响并发访问，但是磁盘资源有限，所以很容易发生请求需要等待而磁盘完成昂贵的压缩操作。对吞吐量和平均响应时间的影响通常很小，但是在更高百分比的情况下，对日志结构化存储引擎的查询响应时间有时会相当长，而B树的行为则相对更具可预测性。
    - 压缩的另一个问题出现在高写入吞吐量：磁盘的有限写入带宽需要在初始写入（记录和刷新内存表到磁盘）和在后台运行的压缩线程之间共享。写入空数据库时，可以使用全磁盘带宽进行初始写入，但数据库越大，压缩所需的磁盘带宽就越多。

# 第四章 编码与演化
### 编码数据的格式
- 向后兼容 （backward compatibility）：新代码可以读旧数据；向前兼容 （forward compatibility）：旧代码可以读新数据。
- JSON，XML，Protocol Buffers，Thrift 和 Avro
- 编码（Encoding）、序列化（serialization）、编组（marshalling）；反过来称为解码（Decoding、解析（Parsing）、反序列化（deserialization）、反编组unmarshalling）
- REST （json）和 SOAP（xml）

### 服务中的数据流
- 在Web服务中，具象状态传输（REST）和远程过程调用（RPC），以及消息传递系统（如Actor和消息队列）
  - RPC 模型试图向远程网络服务发出请求，看起来与在同一进程中调用编程语言中的函数或方法相同（这种抽象称为位置透明）。尽管RPC起初看起来很方便，但这种方法根本上是有缺陷的。网络请求与本地函数调用非常不同。
    - 本地函数调用是可预测的，并且成功或失败，这仅取决于受您控制的参数。网络请求是不可预知的。
    - 本地函数调用要么返回结果，要么抛出异常，或者永远不返回（因为进入无限循环或进程崩溃）。网络请求有另一个可能的结果：由于超时，它可能会返回没有结果。
    - 如果您重试失败的网络请求，可能会发生请求实际上正在通过，只有响应丢失。在这种情况下，重试将导致该操作被执行多次，除非在协议中引入除重机制，本地函数调用没有这个问题。
    - 每次调用本地功能时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且其延迟也是非常可变的。
    - 调用本地函数时，可以高效地将引用（指针）传递给本地内存中的对象。当你发出一个网络请求时，所有这些参数都需要被编码成可以通过网络发送的一系列字节。没关系，如果参数是像数字或字符串这样的基本类型，但是对于较大的对象很快就会变成问题。
  - 使用消息队列，如RabbitMQ，ActiveMQ，HornetQ，NATS和Apache Kafka，与RPC相比，差异在于消息传递通信通常是单向的：发送者通常不期望收到其消息的回复。一个进程可能发送一个响应，但这通常是在一个单独的通道上完成的。这种通信模式是异步的：发送者不会等待消息被传递，而只是发送它，然后忘记它
  - Actor 模型是单个进程中并发的编程模型。逻辑被封装在角色中，而不是直接处理线程（以及竞争条件，锁定和死锁的相关问题）。每个角色通常代表一个客户或实体，它可能有一些本地状态（不与其他任何角色共享），它通过发送和接收异步消息与其他角色通信。消息传送不保证：在某些错误情况下，消息将丢失。由于每个角色一次只能处理一条消息，因此不需要担心线程，每个角色可以由框架独立调度。
